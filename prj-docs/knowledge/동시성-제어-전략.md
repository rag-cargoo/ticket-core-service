# 동시성 제어 전략 (Concurrency Control Strategy)

> **Purpose**: 선착순 좌석 예약 시스템에서 발생하는 데이터 정합성 문제 해결 및 성능 최적화 전략 기록
> **Date**: 2026-02-05

## 0. 이론 배경: 낙관적 락 vs 비관적 락 (Theory)

| 특징 | 낙관적 락 (Optimistic Lock) | 비관적 락 (Pessimistic Lock) |
| :--- | :--- | :--- |
| **기본 사상** | "충돌은 드물 거야. 충돌 나면 그때 해결하자." | "충돌은 빈번할 거야. 아예 못 건드리게 막자." |
| **구현 방식** | **애플리케이션 로직**: 버전 컬럼(`@Version`) 비교. | **DB 쿼리**: `SELECT ... FOR UPDATE`로 물리적 락. |
| **성능 (DB)** | **높음** (락 대기 없음) | **낮음** (대기 발생, 데드락 위험) |
| **충돌 처리** | 예외 발생 (`Exception`) -> 롤백 -> 재시도 필요 | 대기 (`Wait`) -> 순차 처리 -> 성공 |
| **대표 예시** | 게시판 수정, 프로필 업데이트 | 선착순 예매, 재고 차감, 계좌 이체 |

---

## 📋 실험 기록 순서 (Progress)
1. [Step 0: 문제 상황 (락 미적용)](#step-0-문제-상황-락-미적용) - **Completed**
2. [Step 1: 낙관적 락 (Optimistic Lock)](#step-1-낙관적-락-optimistic-lock) - **Completed**
3. [Step 2: 비관적 락 (Pessimistic Lock)](#step-2-비관적-락-pessimistic-lock) - **Completed**
4. [Step 3: Redis 분산 락 (Distributed Lock)](#) - Pending

---

## Step 0: 문제 상황 (락 미적용)

### 1. 실험 시나리오 (Experimental Scenario)
- **테스트 코드**: `동시성_테스트_1_낙관적_락.java` (JPA @Version 주석 처리 후 실행)
- **대상**: 1개 좌석 (Seat ID: 1)
- **부하**: 30명의 스레드가 동시에 예약 API 호출

### 2. 잘못된 구현 방식 (The Wrong Way)
아무런 보호 장치 없이 일반적인 조회와 수정을 반복하는 방식입니다.

```java
// [Service]
@Transactional
public void reserve(Long seatId) {
    Seat seat = seatRepository.findById(seatId).orElseThrow(); // 누구나 동시에 조회 가능
    seat.reserve(); // 각자 메모리 상에서 상태 변경
    // 커밋 시점에 마지막에 들어온 요청이 덮어쓰거나 중복 생성됨 (Race Condition)
}
```

### 3. 실험 결과 (실패)
데이터 정합성이 완전히 깨지는 현상이 발생함. (중복 예약 발생)

#### [수치 결과]
| 항목 | 결과값 | 비고 |
| :--- | :--- | :--- |
| **성공 횟수** | 10건 | **치명적 오류**: 1건이어야 함 |
| **최종 예약 건수** | **10건** | **중복 예약 발생 (Race Condition)** |

---

## Step 1: 낙관적 락 (Optimistic Lock)

### 1. 실험 시나리오 (Experimental Scenario)
- **테스트 코드**: `동시성_테스트_1_낙관적_락.java`
- **대상**: 1개 좌석 (Seat ID: 1)
- **부하**: 30명의 스레드가 동시에 예약 API 호출

### 2. 구현 방법 (How to Apply)
엔티티에 `@Version` 컬럼을 추가하는 것만으로 애플리케이션 레벨의 체크 로직이 활성화됩니다.

```java
// [Entity]
@Version // JPA가 제공하는 낙관적 락 메커니즘
private Long version;
```

### 3. 동작 원리 및 SQL
수정 쿼리 시점에 자동으로 버전 체크 조건이 붙습니다.
```sql
update seats 
set status='RESERVED', version=1 
where id=1 and version=0; -- 처음 읽은 버전이 0일 때만 성공
```

### 4. 실험 결과 및 분석
*   **성공 횟수**: 1건
*   **실패 횟수**: 29건 (ObjectOptimisticLockingFailureException 발생)
*   **결론**: 데이터 정합성은 보장하나, 충돌 시 사용자에게 에러를 반환하므로 선착순 예매에는 한계가 있음.

---

## Step 2: 비관적 락 (Pessimistic Lock)

### 1. 실험 시나리오 (Experimental Scenario)
- **테스트 코드**: `동시성_테스트_2_비관적_락.java`
- **대상**: 1개 좌석 (Seat ID: 1)
- **부하**: 30명의 스레드가 동시에 예약 API 호출

### 2. 구현 방법 (How to Apply)
Spring Data JPA에서 비관적 락을 거는 방법은 크게 두 가지가 있습니다.

#### 방법 A: @Lock 어노테이션 사용 (권장)
JPA가 제공하는 `@Lock` 어노테이션을 사용하여 쿼리 생성 시점에 락 모드를 지정합니다. 이 방식을 쓰면 JPA가 SQL 끝에 자동으로 `FOR UPDATE`를 추가해 줍니다.

```java
// [Repository]
public interface SeatRepository extends JpaRepository<Seat, Long> {
    
    @Lock(LockModeType.PESSIMISTIC_WRITE) // 핵심: 비관적 락 모드 지정
    @Query("SELECT s FROM Seat s WHERE s.id = :id")
    Optional<Seat> findByIdWithPessimisticLock(@Param("id") Long id);
}
```

#### 방법 B: 쿼리에 직접 명시
어노테이션을 사용하지 않고, SQL 또는 JPQL 끝에 직접 락 키워드를 작성합니다. 하지만 JPA 환경에서는 일관성을 위해 `@Lock` 사용을 권장합니다.

### 3. 동작 원리 및 SQL
데이터를 읽는 시점부터 DB가 다른 스레드의 접근을 차단합니다.
```sql
/* 방법 A 적용 시 실행되는 실제 SQL */
select s1_0.id, ... 
from seats s1_0 
where s1_0.id=? 
for update; -- DB 엔진이 해당 행(Row)을 꽉 잡음 (자물쇠)
```

### 4. 결론 (Conclusion)
*   **비관적 락은 쿼리로 해결한다**: 코드 로직이 아니라 DB 엔진의 힘을 빌려 **줄을 세우는 방식**이다.
*   **장점**: 낙관적 락보다 정합성이 강력하고, 불필요한 예외 재시도 로직이 필요 없다.
*   **단점**: 대기 시간이 길어지면 DB 전체 성능에 영향을 준다.

---

## 🚨 락(Lock)만으로는 해결할 수 없는 현실적인 문제

낙관적 락과 비관적 락을 통해 데이터 정합성은 확보했으나, 대규모 트래픽(예: 10,000명 동시 접속) 상황에서는 다음과 같은 **치명적인 한계**가 발생한다.

### 1. 사용자 경험(UX)의 파괴: "만 명 중 한 명만 성공"
- 현재 방식은 1명이 락을 잡고 있는 동안 나머지는 대기하거나 에러를 받는다.
- 만 명의 사용자 중 9,999명은 "이미 예약된 좌석입니다"라는 무뚝뚝한 실패 메시지를 받고 다시 광클을 시도해야 한다. (광클 전쟁 유발)

### 2. 서버 자원 고갈: "DB 커넥션 풀 마비"
- 비관적 락(`FOR UPDATE`)은 DB 커넥션을 점유한 채로 대기한다.
- 동시 요청이 많아지면 모든 커넥션이 락 대기에 빠지게 되어, 예약과 상관없는 다른 API(공연 조회 등)까지 모두 먹통이 되는 **'서버 마비'** 상태에 이른다.

### 💡 해결의 방향: Redis 분산 락과 대기열
- **체력 강화 (Step 3)**: DB보다 훨씬 가볍고 빠른 **Redis**에서 락을 처리하여 DB 부하를 원천 차단한다.
- **질서 확립 (Phase 3)**: 단순히 실패시키는 것이 아니라, **대기열(Queue)**을 도입하여 사용자에게 대기 순번을 부여하고 순차적으로 처리하는 UX를 제공한다.

---

## Step 3: Redis 분산 락 (Distributed Lock)

### Step 3-1: 첫 번째 시도 (실패 사례 - 30/30 성공) ❌

#### 1. 실험 시나리오
- **테스트 코드**: `동시성_테스트_3_분산_락.java`
- **부하**: 30명의 스레드가 동시에 예약 API 호출
- **결과**: **30명 전원 예약 성공 (중복 예약 발생)**

#### 2. 원인 분석 (The Mystery of 30 Successes)
Redis 락을 획득했음에도 불구하고 왜 정합성이 깨졌을까? 여기에는 두 가지 치명적인 함정이 있었다.

**함정 1: 락 해제 시점 vs 트랜잭션 커밋 시점**
- **문제**: Redis 락은 로직이 끝나자마자 `finally` 블록에서 해제된다. 하지만 `@Transactional`에 의한 DB 커밋은 그 이후에 발생한다.
- **현상**: Thread A가 락을 해제하는 순간, 아직 DB에는 데이터가 반영(Commit)되지 않았다. 이때 대기하던 Thread B가 즉시 락을 잡고 진입하면, B는 여전히 `AVAILABLE` 상태의 데이터를 읽게 된다.

**함정 2: 스프링 프록시의 한계 (Internal Call)**
- **문제**: `createReservationWithDistributedLock` 내부에서 `this.createReservation()`을 호출하면, 스프링의 AOP 프록시가 작동하지 않아 `@Transactional`이 무시된다.
- **현상**: 각 DB 작업이 개별 트랜잭션으로 돌거나 커밋 시점이 모호해져서 락의 보호를 전혀 받지 못하게 된다.

#### 3. 교훈 (Lesson Learned)
> **"분산 락의 해제 시점은 반드시 트랜잭션의 커밋 시점보다 늦어야 한다."**
> 또한, 트랜잭션 전파를 위해 별도의 Facade 클래스를 두거나 스프링 빈의 외부 호출을 이용해야 한다.

---

### Step 3-2: 두 번째 시도 (성공 사례 - Facade 패턴 도입) ✅

#### 1. 해결 전략: RedissonLockFacade 도입
트랜잭션과 락의 생명주기를 분리하기 위해 서비스 계층 위에 **Facade 계층**을 두었다.

```java
@Component
public class RedissonLockFacade {
    // ... 락 획득
    // ... reservationService.createReservation(request); (트랜잭션 종료 대기)
    // ... finally { 락 해제 }
}
```

#### 2. 실험 결과 (성공)
- **성공 횟수**: 1건
- **실패 횟수**: 29건
- **최종 예약 건수**: 1건 (정합성 완벽 유지)

#### 3. 핵심 동작 원리
1. **락 획득**: Thread A가 Redis 락 점유.
2. **트랜잭션 실행**: 서비스 계층의 트랜잭션 메서드 호출 및 **DB 커밋 완료**.
3. **락 해제**: 트랜잭션이 완전히 종료된 후 Facade에서 락 해제.
4. **후속 처리**: Thread B가 진입 시, 이미 커밋된 `RESERVED` 상태를 확인하여 중복 예약 방지.

### 4. 최종 결론 (Conclusion)
- **비관적 락**은 DB 자원을 많이 소모하지만 설정이 간편하다.
- **Redis 분산 락**은 설정이 복잡(Facade 필요)하지만, DB 부하를 획득 시점 이전에 차단할 수 있어 **대규모 트래픽에 훨씬 유리**하다.

---
> **Next Work**: 성능 테스트(k6)를 통해 각 단계별 처리량(TPS) 비교 분석 예정.