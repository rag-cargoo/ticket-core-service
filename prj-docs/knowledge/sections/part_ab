
```java
// [Repository]
public interface SeatRepository extends JpaRepository<Seat, Long> {
    
    @Lock(LockModeType.PESSIMISTIC_WRITE) // 핵심: 비관적 락 모드 지정
    @Query("SELECT s FROM Seat s WHERE s.id = :id")
    Optional<Seat> findByIdWithPessimisticLock(@Param("id") Long id);
}
```

#### 방법 B: 쿼리에 직접 명시
어노테이션을 사용하지 않고, SQL 또는 JPQL 끝에 직접 락 키워드를 작성합니다. 하지만 JPA 환경에서는 일관성을 위해 `@Lock` 사용을 권장합니다.

### 3. 동작 원리 및 SQL
데이터를 읽는 시점부터 DB가 다른 스레드의 접근을 차단합니다.
```sql
/* 방법 A 적용 시 실행되는 실제 SQL */
select s1_0.id, ... 
from seats s1_0 
where s1_0.id=? 
for update; -- DB 엔진이 해당 행(Row)을 꽉 잡음 (자물쇠)
```

### 4. 결론 (Conclusion)
*   **비관적 락은 쿼리로 해결한다**: 코드 로직이 아니라 DB 엔진의 힘을 빌려 **줄을 세우는 방식**이다.
*   **장점**: 낙관적 락보다 정합성이 강력하고, 불필요한 예외 재시도 로직이 필요 없다.
*   **단점**: 대기 시간이 길어지면 DB 전체 성능에 영향을 준다.

---

## 🚨 락(Lock)만으로는 해결할 수 없는 현실적인 문제

낙관적 락과 비관적 락을 통해 데이터 정합성은 확보했으나, 대규모 트래픽(예: 10,000명 동시 접속) 상황에서는 다음과 같은 **치명적인 한계**가 발생한다.

### 1. 사용자 경험(UX)의 파괴: "만 명 중 한 명만 성공"
- 현재 방식은 1명이 락을 잡고 있는 동안 나머지는 대기하거나 에러를 받는다.
- 만 명의 사용자 중 9,999명은 "이미 예약된 좌석입니다"라는 무뚝뚝한 실패 메시지를 받고 다시 광클을 시도해야 한다. (광클 전쟁 유발)

### 2. 서버 자원 고갈: "DB 커넥션 풀 마비"
- 비관적 락(`FOR UPDATE`)은 DB 커넥션을 점유한 채로 대기한다.
- 동시 요청이 많아지면 모든 커넥션이 락 대기에 빠지게 되어, 예약과 상관없는 다른 API(공연 조회 등)까지 모두 먹통이 되는 **'서버 마비'** 상태에 이른다.

### 💡 해결의 방향: Redis 분산 락과 대기열
- **체력 강화 (Step 3)**: DB보다 훨씬 가볍고 빠른 **Redis**에서 락을 처리하여 DB 부하를 원천 차단한다.
- **질서 확립 (Phase 3)**: 단순히 실패시키는 것이 아니라, **대기열(Queue)**을 도입하여 사용자에게 대기 순번을 부여하고 순차적으로 처리하는 UX를 제공한다.

---

## Step 3: Redis 분산 락 (Distributed Lock)

### Step 3-1: 첫 번째 시도 (실패 사례 - 30/30 성공) ❌

#### 1. 실험 시나리오
- **테스트 코드**: `동시성_테스트_3_분산_락.java`
- **부하**: 30명의 스레드가 동시에 예약 API 호출
- **결과**: **30명 전원 예약 성공 (중복 예약 발생)**

#### 2. 원인 분석 (The Mystery of 30 Successes)
Redis 락을 획득했음에도 불구하고 왜 정합성이 깨졌을까? 여기에는 두 가지 치명적인 함정이 있었다.

**함정 1: 락 해제 시점 vs 트랜잭션 커밋 시점**
- **문제**: Redis 락은 로직이 끝나자마자 `finally` 블록에서 해제된다. 하지만 `@Transactional`에 의한 DB 커밋은 그 이후에 발생한다.
- **현상**: Thread A가 락을 해제하는 순간, 아직 DB에는 데이터가 반영(Commit)되지 않았다. 이때 대기하던 Thread B가 즉시 락을 잡고 진입하면, B는 여전히 `AVAILABLE` 상태의 데이터를 읽게 된다.

**함정 2: 스프링 프록시의 한계 (Internal Call)**
- **문제**: `createReservationWithDistributedLock` 내부에서 `this.createReservation()`을 호출하면, 스프링의 AOP 프록시가 작동하지 않아 `@Transactional`이 무시된다.
- **현상**: 각 DB 작업이 개별 트랜잭션으로 돌거나 커밋 시점이 모호해져서 락의 보호를 전혀 받지 못하게 된다.

#### 3. 교훈 (Lesson Learned)
> **"분산 락의 해제 시점은 반드시 트랜잭션의 커밋 시점보다 늦어야 한다."**
> 또한, 트랜잭션 전파를 위해 별도의 Facade 클래스를 두거나 스프링 빈의 외부 호출을 이용해야 한다.

---

### Step 3-2: 두 번째 시도 (성공 사례 - Facade 패턴 도입) ✅

#### 1. Facade(파사드) 패턴이란?
'건물의 정면'이라는 뜻으로, 내부의 복잡한 로직들을 하나의 겉껍데기 클래스로 감싸서 밖에서는 단순하게 보이게 만드는 디자인 패턴이다.

#### 2. 왜 Facade가 필요한가? (트랜잭션의 함정)
스프링의 `@Transactional`은 메서드가 완전히 끝날 때 DB에 내용을 저장(Commit)한다.
- **Service 내부에서 락을 걸면**: 메서드 끝에서 락을 먼저 풀고, 그 **다음에** DB 저장이 일어난다. (그 사이 찰나에 다른 놈이 들어와서 사고 발생!)
- **Facade를 사용하면**: 
  1. Facade에서 락을 잡는다.
  2. Service의 트랜잭션 메서드를 부른다. (DB 저장까지 완벽히 끝날 때까지 기다림)
  3. **DB 저장이 확실히 끝난 뒤에** Facade에서 락을 푼다.

#### 3. 해결 전략: RedissonLockFacade 전체 코드
생략 없이 실제 구현된 코드를 통해 락과 트랜잭션의 조율 과정을 확인한다.

```java
@Component
@RequiredArgsConstructor
public class RedissonLockFacade {

    private final RedissonClient redissonClient;
    private final ReservationService reservationService;

    public ReservationResponse createReservation(ReservationRequest request) {
